{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Let's get started...\n#First, import all the required libraries.\nimport pandas as pd\nimport numpy as np\nimport re                                             #To perform operations on regular expression.\nfrom sklearn.tree import DecisionTreeClassifier       #We'll use a decision tree classifier to predict results.\nfrom sklearn.model_selection import cross_val_score\nimport warnings                                       #ignoring the warnings generated during some computation\nwarnings.filterwarnings(\"ignore\")\ntrain_data = pd.read_csv('../input/train.csv')        #loading the train data\ntest_data = pd.read_csv('../input/test.csv')          #loading the test data\ncomplete_data = [train_data, test_data]               #all data grouped together","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"print( train_data[[\"Pclass\",\"Survived\"]].groupby([\"Pclass\"], as_index = False).mean() )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( train_data[[\"Sex\",\"Survived\"]].groupby([\"Sex\"], as_index = False).mean() )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for data in complete_data:\n    data['family_size'] = data['SibSp'] + data['Parch'] + 1\nprint( train_data[[\"family_size\",\"Survived\"]].groupby([\"family_size\"], as_index = False).mean() )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for data in complete_data:\n    data['is_alone'] = 0\n    data.loc[data['family_size'] == 1, 'is_alone'] = 1\nprint (train_data[['is_alone', 'Survived']].groupby(['is_alone'], as_index=False).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for data in complete_data:\n    data['Embarked'] = data['Embarked'].fillna('S')\nprint( train_data[[\"Embarked\",\"Survived\"]].groupby([\"Embarked\"], as_index = False).mean() )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for data in complete_data:\n    data['Fare'] = data['Fare'].fillna(data['Fare'].median())\ntrain_data['category_fare'] = pd.qcut(train_data['Fare'], 4)\nprint( train_data[[\"category_fare\",\"Survived\"]].groupby([\"category_fare\"], as_index = False).mean() )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for data in complete_data:\n    age_avg  = data['Age'].mean()\n    age_std  = data['Age'].std()\n    age_null = data['Age'].isnull().sum()\n    #The feature 'Age' has some missing values. We'll fill it with some random values for easy grouping.\n    random_list = np.random.randint(age_avg - age_std, age_avg + age_std , size = age_null)\n    data['Age'][np.isnan(data['Age'])] = random_list\n    data['Age'] = data['Age'].astype(int)\n\ntrain_data['category_age'] = pd.cut(train_data['Age'], 5)               #grouping data into a set of 5\nprint( train_data[[\"category_age\",\"Survived\"]].groupby([\"category_age\"], as_index = False).mean() )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The feature 'Name' contains different titles of different persons.\n#We'll extract the all titles and group them under a list called 'title'\n#This will help us to get clean data.\ndef get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\. ', name)\n    if title_search:\n        return title_search.group(1)\n    return \"\"\n\nfor data in complete_data:\n    data['title'] = data['Name'].apply(get_title)\n\nfor data in complete_data:\n    data['title'] = data['title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'],'Rare')\n    data['title'] = data['title'].replace('Mlle','Miss')\n    data['title'] = data['title'].replace('Ms','Miss')\n    data['title'] = data['title'].replace('Mme','Mrs')\n    \nprint(pd.crosstab(train_data['title'], train_data['Sex']))\nprint(\"----------------------\")\nprint(train_data[['title','Survived']].groupby(['title'], as_index = False).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Mapping the data.\n#ML algorithms are efficient with numerical values. \n#We'll convert each of the feature values into a designated numerical value.\n#We'll drop some of the unnecessary features which might have an impact on our outcome.\nfor data in complete_data:\n\n    #Mapping Sex\n    sex_map = { 'female':0 , 'male':1 }\n    data['Sex'] = data['Sex'].map(sex_map).astype(int)\n\n    #Mapping Title\n    title_map = {'Mr':1, 'Miss':2, 'Mrs':3, 'Master':4, 'Rare':5}\n    data['title'] = data['title'].map(title_map)\n    data['title'] = data['title'].fillna(0)\n\n    #Mapping Embarked\n    embark_map = {'S':0, 'C':1, 'Q':2}\n    data['Embarked'] = data['Embarked'].map(embark_map).astype(int)\n\n    #Mapping Fare\n    data.loc[ data['Fare'] <= 7.91, 'Fare']                            = 0\n    data.loc[(data['Fare'] > 7.91) & (data['Fare'] <= 14.454), 'Fare'] = 1\n    data.loc[(data['Fare'] > 14.454) & (data['Fare'] <= 31), 'Fare']   = 2\n    data.loc[ data['Fare'] > 31, 'Fare']                               = 3\n    data['Fare'] = data['Fare'].astype(int)\n\n    #Mapping Age\n    data.loc[ data['Age'] <= 16, 'Age']                       = 0\n    data.loc[(data['Age'] > 16) & (data['Age'] <= 32), 'Age'] = 1\n    data.loc[(data['Age'] > 32) & (data['Age'] <= 48), 'Age'] = 2\n    data.loc[(data['Age'] > 48) & (data['Age'] <= 64), 'Age'] = 3\n    data.loc[ data['Age'] > 64, 'Age']                        = 4\n\n#Feature Selection\n#Create list of columns to drop\ndrop_elements = [\"Name\", \"Ticket\", \"Cabin\", \"SibSp\", \"Parch\", \"family_size\"]\n\n#Drop columns from both data sets\ntrain_data = train_data.drop(drop_elements, axis = 1)\ntrain_data = train_data.drop(['PassengerId','category_fare', 'category_age'], axis = 1)\ntest_data = test_data.drop(drop_elements, axis = 1)\n\n#Print ready to use data\nprint(train_data.head(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting the data.\n#Train set & Test set.\nX_train = train_data.drop(\"Survived\", axis=1)\nY_train = train_data[\"Survived\"]\nX_test  = test_data.drop(\"PassengerId\", axis=1).copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Making predictions.\n#Using Decision Tree classifier from 'sklearn.tree' \ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\naccuracy = round(decision_tree.score(X_train, Y_train) * 100, 2)\nprint(\"Model Accuracy: \",accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create a CSV with results\nsubmission = pd.DataFrame({\n    \"PassengerId\": test_data[\"PassengerId\"],\n    \"Survived\": Y_pred\n})\nsubmission.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}